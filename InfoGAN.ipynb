{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation of InfoGAN:Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets, by Xi Chen et al\n",
    "# The Q loss function can be modified in many ways\n",
    "# MSE for continuous and fake/real decisions\n",
    "# Cross Entropy for Latent Code\n",
    "# Can also Use L1 distance for latent code\n",
    "# Feature Smoothing not implemented yet\n",
    "# Implement Minibatch Discrimination and Virtual batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages and modules\n",
    "import numpy as np\n",
    "import itertools\n",
    "import math\n",
    "import os\n",
    "import torch    # Pytorch 0.4\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "os.chdir(\"/home/agastya/Downloads\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 200    # number of epochs of training, int, default=200\n",
    "batch_size = 64    # size of the batches, int, default=64\n",
    "lr = 0.0002    # learning rate, float, default=0.0002\n",
    "b1 = 0.5    # first order momentum gradient decay ADAM, float, default=0.5\n",
    "b2 = 0.999    # second order momentum gradient decay ADAM, float, default=0.999\n",
    "n_cpu = 8    # number of cpu threads to use during batch generation, int, default=8\n",
    "latent_dim = 62    # dimensionality of latent space, int, default=100\n",
    "code_dim = 2    # Latent code, int, default = 2\n",
    "img_size = 32    # size of each image dimension, int, default=28\n",
    "channels = 1    # number of image channels, int, default=1\n",
    "sample_interval = 400    # interval between image samples, int, default=400\n",
    "n_classes = 10    # number of classes for dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1.0 Data Preparation and Preprocessing\n",
    "# Use transforms.Resize(img_size) to resize the image into (batch_size, 1, img_size, img_size)\n",
    "def mnist_data():\n",
    "    compose = transforms.Compose([\n",
    "         transforms.Resize(img_size),\n",
    "         transforms.ToTensor(),\n",
    "         transforms.Normalize((.5, .5, .5), (.5, .5, .5)) \n",
    "         #Normalized to (-1,1) so as to mimic a tanh activation function\n",
    "        ])\n",
    "    out_dir = './dataset'\n",
    "    return datasets.MNIST(root=out_dir, train=True, transform=compose, download=True)\n",
    "data = mnist_data()\n",
    "data_loader = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weights initialization\n",
    "# Gaussian Distribution works the best\n",
    "def init_weights(m):\n",
    "    \n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias.data, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = True if torch.cuda.is_available() else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns one hot encoded variable\n",
    "def to_categorical(y, num_columns):\n",
    "    \n",
    "    y_cat = np.zeros((y.shape[0], num_columns))\n",
    "    y_cat[range(y.shape[0]), y] = 1\n",
    "    return torch.tensor(y_cat, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generator NN\n",
    "# DCGAN, with input dims concatenated with classes and latent code\n",
    "# Upsampling is used instead of ConvTranspose\n",
    "# Normal convolution is used with kernel_size=3, and dimensions are retained with appropriate padding\n",
    "class Generator(nn.Module):\n",
    "    \n",
    "    def __init__(self, latent_dims, code_dims, n_classes, img_size):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.negative_slope = 0.2\n",
    "        self.input_dims = latent_dims + code_dims + n_classes\n",
    "        self.init_size = img_size//4\n",
    "        \n",
    "        self.layer1 = nn.Linear(self.input_dims, 128*self.init_size**2)\n",
    "        self.batchnorm1 = nn.BatchNorm2d(128)\n",
    "        self.upsample1 = nn.Upsample(scale_factor=2)\n",
    "        self.conv1 = nn.Conv2d(128, 128, 3, stride=1, padding=1)\n",
    "        self.batchnorm2 = nn.BatchNorm2d(128, 0.8)\n",
    "        self.upsample2 = nn.Upsample(scale_factor=2)\n",
    "        self.conv2 = nn.Conv2d(128, 64, 3, stride=1, padding=1)\n",
    "        self.batchnorm3 = nn.BatchNorm2d(64, 0.8)\n",
    "        self.conv3 = nn.Conv2d(64, 1, 3, stride=1, padding=1)\n",
    "        \n",
    "    def forward(self, noise, labels, code):\n",
    "        \n",
    "        out = torch.cat((noise, labels, code), -1)\n",
    "        out = self.layer1(out)\n",
    "        out = out.view(out.size(0), 128, self.init_size, self.init_size)\n",
    "        out = self.upsample1(self.batchnorm1(out))\n",
    "        out = F.leaky_relu_(self.batchnorm2(self.conv1(out)), self.negative_slope)\n",
    "        out = self.conv2(self.upsample2(out))\n",
    "        out = F.leaky_relu_(self.batchnorm3(out))\n",
    "        out = F.tanh(self.conv3(out))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator NN\n",
    "# Convolutional layers with dropout and batch normalization\n",
    "# Feature extraction and abstraction layers are same for adversarial, continuous and mutual_information objectives\n",
    "# Adversarial layer - mapping to a sigmoid layer, outputting whether real/fake\n",
    "# Auxiliary layer - mapping to n_classes and then a softmax layer, outputting probabilities of class label\n",
    "# Latent Layer - Mapping to latent code dimensions, which can be done in two ways\n",
    "# MSE with the output being the actual value of latent code\n",
    "# CrossEntropy - with the output being the mean and variance of the gaussian distribution the latent code is picked from\n",
    "class Discriminator(nn.Module):\n",
    "\n",
    "    def __init__(self, img_size, n_classes, code_dims):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.negative_slope = 0.2\n",
    "\n",
    "        # Discriminator block\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1)\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1)\n",
    "        self.dropout2 = nn.Dropout2d(0.25)\n",
    "        self.batchnorm2 = nn.BatchNorm2d(32, 0.8)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1)\n",
    "        self.dropout3 = nn.Dropout2d(0.25)\n",
    "        self.batchnorm3 = nn.BatchNorm2d(64, 0.8)\n",
    "        self.conv4 = nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1)\n",
    "        self.dropout4 = nn.Dropout2d(0.25)\n",
    "        self.batchnorm4 = nn.BatchNorm2d(128, 0.8)\n",
    "\n",
    "        # The height and width of downsampled image\n",
    "        downsampled_size = img_size//2**4\n",
    "\n",
    "        # Output layers\n",
    "        self.adv_layer = nn.Linear(128*downsampled_size**2, 1)\n",
    "        self.aux_layer = nn.Sequential(\n",
    "            nn.Linear(128*downsampled_size**2, n_classes),\n",
    "            nn.Softmax())\n",
    "        self.latent_layer = nn.Linear(128*downsampled_size**2, code_dims)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        out = self.dropout1(F.leaky_relu_(self.conv1(x), self.negative_slope))\n",
    "        out = self.batchnorm2(self.dropout2(F.leaky_relu_(self.conv2(out), self.negative_slope)))\n",
    "        out = self.batchnorm3(self.dropout3(F.leaky_relu_(self.conv3(out), self.negative_slope)))\n",
    "        out = self.batchnorm4(self.dropout4(F.leaky_relu_(self.conv4(out), self.negative_slope)))\n",
    "        out = out.view(out.shape[0], -1)\n",
    "\n",
    "        validity = self.adv_layer(out)\n",
    "        label = self.aux_layer(out)\n",
    "        latent_code = self.latent_layer(out)\n",
    "\n",
    "        return validity, label, latent_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversarial_loss = nn.MSELoss()\n",
    "categorical_loss = nn.CrossEntropyLoss()\n",
    "continuous_loss = nn.MSELoss()\n",
    "generator = Generator(latent_dim, code_dim, n_classes, img_size)\n",
    "discriminator = Discriminator(img_size, n_classes, code_dim)\n",
    "generator.apply(init_weights)\n",
    "discriminator.apply(init_weights)\n",
    "if cuda:\n",
    "    generator.cuda()\n",
    "    discriminator.cuda()\n",
    "    adversarial_loss.cuda()\n",
    "    categorical_loss.cuda()\n",
    "    continuous_loss.cuda()\n",
    "gen_optim = optim.Adam(generator.parameters(), lr=lr, betas=(b1, b2))\n",
    "disc_optim = optim.Adam(discriminator.parameters(), lr=lr, betas=(b1, b2))\n",
    "infogan_optim = optim.Adam(itertools.chain(generator.parameters(), discriminator.parameters()), \n",
    "                            lr = lr, betas=(b1, b2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regularization factor\n",
    "lambda_cat = 1\n",
    "lambda_con = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample random noise froma Gaussian Distribution\n",
    "def noise(batch_size, latent_dim):\n",
    "    n = torch.tensor(np.random.normal(0, 1, (batch_size, latent_dim)), dtype=torch.float)\n",
    "    if torch.cuda.is_available():\n",
    "        return n.cuda()\n",
    "    else:\n",
    "        return n\n",
    "\n",
    "# Returns an array of 1's for real data\n",
    "def real_data_targets(size):\n",
    "    data = torch.tensor(torch.ones(size, 1), dtype=torch.float)\n",
    "    if torch.cuda.is_available():\n",
    "        return data.cuda()\n",
    "    else:\n",
    "        return data\n",
    "\n",
    "# Returns a array of 0's for fake data\n",
    "def fake_data_targets(size):\n",
    "    data = torch.tensor(torch.zeros(size, 1), dtype=torch.float)\n",
    "    if torch.cuda.is_available():\n",
    "        return data.cuda()\n",
    "    else:\n",
    "        return data\n",
    "\n",
    "# Random data labels for generator from (0,n_classes]\n",
    "def fake_data_labels(size):\n",
    "    labels = torch.tensor(torch.randint(low=0,high=10, size=(1,size)).view(-1), dtype=torch.long)\n",
    "    if torch.cuda.is_available():\n",
    "        return labels.cuda()\n",
    "    else:\n",
    "        return labels\n",
    "    \n",
    "# Sample latent code from a gaussian distribution\n",
    "def code(batch_size, code_dim):\n",
    "    data = torch.tensor(np.random.uniform(-1, 1, (batch_size, code_dim)), dtype=torch.float)\n",
    "    if torch.cuda.is_available():\n",
    "        return data.cuda()\n",
    "    else:\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gen(optimizer, gen_images):\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    target = torch.tensor(real_data_targets(gen_images.size(0)))\n",
    "    predictions, _, __ = discriminator(gen_images)\n",
    "    loss = adversarial_loss(predictions, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_disc(optimizer, real_data, fake_data):\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Loss for real images\n",
    "    real_targets = torch.tensor(real_data_targets(real_data.size(0)))\n",
    "    real_predictions, _, __ = discriminator(real_data)\n",
    "    real_loss = adversarial_loss(real_predictions, real_targets)\n",
    "    \n",
    "    # Loss for generated images\n",
    "    fake_targets = torch.tensor(fake_data_targets(fake_data.size(0)))\n",
    "    fake_predictions, _, __ = discriminator(fake_data)\n",
    "    fake_loss = adversarial_loss(fake_predictions, fake_targets)\n",
    "    \n",
    "    total_loss = (real_loss + fake_loss)/2\n",
    "    total_loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_info(optimizer):\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    labels = fake_data_labels(batch_size)\n",
    "    sampled_labels = torch.tensor(labels, dtype = torch.long, requires_grad=True)\n",
    "    gt_labels = torch.tensor(labels, dtype=torch.long)\n",
    "    \n",
    "    gen_info_noise = torch.tensor(noise(batch_size, latent_dim), requires_grad=True)\n",
    "    gen_info_labels = torch.tensor(to_categorical(sampled_labels.detach().numpy(), n_classes), requires_grad=True)\n",
    "    gen_info_code = torch.tensor(code(batch_size, code_dim))\n",
    "    \n",
    "    info_imgs = generator(gen_info_noise, gen_info_labels, gen_info_code)\n",
    "    _, label_predictions, code_predictions = discriminator(info_imgs)\n",
    "    \n",
    "    info_loss = lambda_cat*categorical_loss(label_predictions, gt_labels) + lambda_con*continuous_loss(code_predictions, gen_info_code)\n",
    "    info_loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return info_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainGAN(num_epochs):\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        for batch, (real_data, real_labels) in enumerate(data_loader):\n",
    "            \n",
    "            real_data = torch.tensor(real_data, dtype=torch.float, requires_grad=True)\n",
    "            real_labels = torch.tensor(to_categorical(real_labels.numpy(), num_columns=n_classes), dtype=torch.long, requires_grad=True)\n",
    "            \n",
    "            # Initialize inputs\n",
    "            gen_input_noise = torch.tensor(noise(batch_size, latent_dim), requires_grad=True)\n",
    "            gen_input_labels = torch.tensor(to_categorical(fake_data_labels(batch_size).detach().numpy(),\n",
    "                                                           num_columns=n_classes), requires_grad=True)\n",
    "            gen_input_code = torch.tensor(code(batch_size, code_dim), requires_grad=True)\n",
    "            \n",
    "            # Train Generator\n",
    "            gen_images = generator(gen_input_noise, gen_input_labels, gen_input_code)\n",
    "            gen_loss = train_gen(gen_optim, gen_images)\n",
    "            \n",
    "            # Train Discriminator\n",
    "            fake_data = gen_images.detach()\n",
    "            disc_loss = train_disc(disc_optim, real_data, fake_data)\n",
    "            \n",
    "            # Information Loss\n",
    "            info_loss = train_info(infogan_optim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agastya/anaconda3/envs/cpu1.8/lib/python3.6/site-packages/torch/nn/modules/container.py:91: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    }
   ],
   "source": [
    "trainGAN(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
